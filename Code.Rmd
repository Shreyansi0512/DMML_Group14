---
title: "EDA Code"
author: "Shreyansi Jain"
date: "2023-03-07"
output: html_document
---

```{r setup, include=FALSE, echo = FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries}
library(gmodels) # Cross Tables [CrossTable()]
library(ggmosaic) # Mosaic plot with ggplot [geom_mosaic()]
library(corrplot) # Correlation plot [corrplot()]
library(ggpubr) # Arranging ggplots together [ggarrange()]
library(cowplot) # Arranging ggplots together [plot_grid()]
library(caret) # ML [train(), confusionMatrix(), createDataPartition(), varImp(), trainControl()]
library(ROCR) # Model performance [performance(), prediction()]
library(plotROC) # ROC Curve with ggplot [geom_roc()]
library(pROC) # AUC computation [auc()]
library(PRROC) # AUPR computation [pr.curve()]
library(rpart) # Decision trees [rpart(), plotcp(), prune()]
library(rpart.plot) # Decision trees plotting [rpart.plot()]
library(ranger) # Optimized Random Forest [ranger()]
library(lightgbm) # Light GBM [lgb.train()]
library(xgboost) # XGBoost [xgb.DMatrix(), xgb.train()]
library(MLmetrics) # Custom metrics (F1 score for example)
library(tidyverse) # Data manipulation
library(doMC) # Parallel processing
```


```{r}
data = read.csv("group_14.csv")
data=replace(data,data=='',"missing")
head(data)
data %>% 
  summarise_all(list(~sum(. == "missing"))) %>% 
  gather(key = "variable", value = "no_missing") %>% 
  arrange(-no_missing)

#Defining crosstable to be used in our analysis
Crosstab = function(df, var1, var2){
  # df: dataframe containing both columns to cross
  # var1, var2: columns to cross together.
  CrossTable(df[, var1], df[, var2],
             prop.r = T,
             prop.c = F,
             prop.t = F,
             prop.chisq = F,
             dnn = c(var1, var2))
}

```

```{r}
#Treating missing values

#Default variable
table(data$default)

#As we can see from the table, only 1 individual replied with "yes", that they have credit in default. 
#78.5% individuals answered "no" and 21.5% did not reply at all. Hence, this variable is of not much significance as we get no information from it. Thus, we would remove this from our dataset.

data2=data %>%
  select(-default)

#Education 

Crosstab(data2,"education","y")
#Removing missing values from the data, since less than 5% of the data has missing values for this field and the proportion of the response variable for these values is the same as the data at a whole. It is better to omit these values altogether.

data2=data2%>%
  filter(education!="missing")

#Housing

Crosstab(data2,"housing","y")

chisq.test(data2$housing,data2$y)

#Since, the chi-square test for this variable has p-value less than 0.05 there is a significant association with the response variable. Hence, we would keep this in our dataset.

#Removing missing values from the data, since less than 5% of the data has missing values for this field and the proportion of the response variable for these values is the same as the data at a whole. It is better to omit these values altogether.

data2=data2%>%
  filter(housing!="missing")

#Loan

Crosstab(data2,"loan","y")
chisq.test(data2$loan,data2$y)

#Since, the chi-square test for this variable has p-value more than 0.05 there is no significant association with the response variable. Hence, we would exclude this from our dataset.

data2= data2 %>%
  select(-loan)

#Job
table(data2$job)

Crosstab(data2,"job","y")

#Removing missing values from the data, since less than 5% of the data has missing values for this field and the proportion of the response variable for these values is the same as the data at a whole. It is better to omit these values altogether.

data2=data2%>%
  filter(job!="missing")

#Marital status

Crosstab(data2,"marital","y")

#Removing missing values from the data, since less than 5% of the data has missing values for this field and the proportion of the response variable for these values is the same as the data at a whole. It is better to omit these values altogether.

data2=data2%>%
  filter(marital!="missing")
dim(data2)
dim(data)

data2 %>% 
  summarise_all(list(~sum(. == "missing"))) %>% 
  gather(key = "variable", value = "no_missing") %>% 
  arrange(-no_missing)

#No missing values left in our final dataset.
```

```{r}
#Train-test split.Using 80%/20% split.
set.seed(123)

n=nrow(data2)
ind=sample(c(1:n),0.8*n)
data.train=data2[ind,]
data.test=data2[-ind,]

dim(data.train)
dim(data.test)
```

```{r}
#EXPLORATORY DATA ANALYSIS
#age
data.train %>% ggplot(aes(age)) +
  geom_histogram(color = 'white')
data.train %>% ggplot(aes(age, color = factor(y))) + 
  geom_density() +
  scale_x_continuous(breaks = seq(0, 100, 10)) +
  guides(color = guide_legend(title = 'Subscribed'))
#age group 30-58 more likely to say no. and more importantly
#product was subscribed with high likelihood after the age of ~60


#job
data.train %>% count(job) %>%
  ggplot(aes(y = fct_reorder(job, n), x = n))+
  geom_col() +
  labs(x = 'Count', y = 'Job') + 
  scale_x_continuous(breaks = seq(0, 2000, 200))

##comparison of proportion of 'yes' across job types
data.train %>% ggplot(aes(y = fct_rev(fct_infreq(job)), fill = y))+
     geom_bar(position = 'fill', color = 'black') +
     scale_fill_brewer(palette = 'Pastel1') +
     labs(x = 'proportion', y = 'Job')

#the high proportion of 'retired' job category resulting in 'yes'
#supports our previous observation related to age variable.


#marital
data.train %>% count(marital, y) %>% ungroup() %>%
  group_by(marital) %>% mutate(prop = n / sum(n)) %>%
  pivot_wider(names_from = y, values_from = c(n, prop))

data.train %>% ggplot(aes(x = marital, fill = y)) +
  geom_bar(position = 'fill', color = 'black') +
  scale_fill_brewer(palette = 'Pastel1')
#the proportion that resulted in 'yes' is not markedly different across marital status.


#education
data.train %>% ggplot(aes(y = education, y)) +
  geom_count() +
  labs(y = 'Education', x = 'count')
#Count of 'yes' for people with 'University degree' seems to be high

data.train %>% ggplot(aes(y = education, fill = y)) +
  geom_bar(position = 'fill')
#the proportion related to illiterate category is misleading because
#the overall sample size is very small
#other than that, 'university degree' and 'professional course' have a
#higher proportion


#housing
data.train %>% count(housing, y)

data.train %>% ggplot(aes(housing, fill = y)) + geom_bar(position = 'fill')

```



```{r}
#Contact
data.train %>% 
  ggplot() +
  aes(x = contact, y = after_stat(count)/nrow(data.train), fill = y) +
  geom_bar()

#Here, we can see that there have been more term deposits from cellular responders, 14.5% as compared to telephone responders which is just 5.6%.

#Month

Crosstab(data.train,"month","y")

data.train=data.train %>%
  mutate(month=factor(data.train$month,levels=c("jan","feb","mar","apr","may","jun","jul","aug","sep","oct",
                                                "nov","dec")))

data.train %>% 
  ggplot() +
  aes(x = month, y = after_stat(count)/nrow(data.train), fill = y) +
  geom_bar()

#From the barplot, we can see that there has been no contact in the months of January and February. Most contact has been made in May almost 33.7%, but most of the people declined to deposit here as well. Least contact has been made in December.

#Day of the week

Crosstab(data.train,"day_of_week","y")

data.train=data.train %>%
  mutate(day_of_week=factor(data.train$day_of_week,levels=c("mon","tue","wed","thu","fri","sat","sun")))

data.train %>% 
  ggplot() +
  aes(x = day_of_week, y = after_stat(count)/nrow(data.train), fill = y) +
  geom_bar()

#Duration

data.train=data.train %>%
  select(-duration)

#There doesn't seem to be a significant relationship between our response variable and duration. As our goal is to know how many people will subscribe to the term deposit, it is not really possible to know the duration of the call beforehand.


#Campaign

data.train %>%
  ggplot()+
  aes(x=campaign)+
  geom_bar()

#We can see that for more than 15 calls, every responder has declined for the term deposit. If we look at the data only for a total a 15 calls-

data.train %>%
  filter(campaign<=15) %>%
  ggplot()+
  aes(x=campaign)+
  geom_bar()

data.train %>%
  mutate(campaign=ifelse(campaign<=15,"Less Than 15","More Than 15"))

```

```{r}

# Pdays : Number of days passed after client was last contacted by a previous campaign

# Distribution of data
table(data.train$pdays)

# The number 999 means that the client has not been contacted before, this constitutes as the majority of the clients. 
# This variable can be used to check if previous contact with a client is beneficial, but we need to convert this variable

data.train = data.train %>%
              mutate(n_contact = if_else(pdays == 999,0,1)) %>%
              select(-pdays)

Crosstab(data.train,'n_contact','y')

chisq.test(data.train$n_contact,data.train$y)
# It seems that when a client is contacted before,they are more receptive towards saying Yes
# This is verified with the chisq test as well.

# previous : Number of times a client has been contacted before this campaign
table(data.train$previous)

# This variable will provide the same information after encoding it to whether or not a previous contact has been made with the client or not.

# Poutcome : Outcome of the previous campaign on the respective client.


table(data.train$poutcome)

Crosstab(data.train,'poutcome','y')

```

```{r}
# Exploratory Data Analysis

# All Continuous variables

summary(data.train)

num_variables = c('age','emp.var.rate','cons.price.idx','cons.conf.idx','euribor3m','nr.employed')
library(GGally)

ggpairs(data.train,columns = num_variables)

corrplot(cor(data.train[num_variables]))

for (col in num_variables){
  
  plot = ggplot(data = data.train,aes(x = data.train[,col])) +
    geom_histogram()
  print(plot)
}
?aes



Crosstab(data.train,"contact","y")
```

