---
title: "EDA Code"
author: "Shreyansi Jain"
date: "2023-03-07"
output: html_document
---

```{r setup, include=FALSE, echo = FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries}
library(gmodels) # Cross Tables [CrossTable()]
library(ggmosaic) # Mosaic plot with ggplot [geom_mosaic()]
library(corrplot) # Correlation plot [corrplot()]
library(ggpubr) # Arranging ggplots together [ggarrange()]
library(cowplot) # Arranging ggplots together [plot_grid()]
library(caret) # ML [train(), confusionMatrix(), createDataPartition(), varImp(), trainControl()]
library(ROCR) # Model performance [performance(), prediction()]
library(plotROC) # ROC Curve with ggplot [geom_roc()]
library(pROC) # AUC computation [auc()]
library(PRROC) # AUPR computation [pr.curve()]
library(rpart) # Decision trees [rpart(), plotcp(), prune()]
library(rpart.plot) # Decision trees plotting [rpart.plot()]
library(ranger) # Optimized Random Forest [ranger()]
library(lightgbm) # Light GBM [lgb.train()]
library(xgboost) # XGBoost [xgb.DMatrix(), xgb.train()]
library(MLmetrics) # Custom metrics (F1 score for example)
library(tidyverse) # Data manipulation
library(doMC) # Parallel processing
library(janitor)
```


```{r}
data = read.csv("group_14.csv")
data=replace(data,data=='',"missing")
head(data)
data %>% 
  summarise_all(list(~sum(. == "missing"))) %>% 
  gather(key = "variable", value = "no_missing") %>% 
  arrange(-no_missing)

#Defining crosstable to be used in our analysis
Crosstab = function(df, var1, var2){
  # df: dataframe containing both columns to cross
  # var1, var2: columns to cross together.
  CrossTable(df[, var1], df[, var2],
             prop.r = T,
             prop.c = F,
             prop.t = F,
             prop.chisq = F,
             dnn = c(var1, var2))
}

```

```{r}
#Treating missing values

#Default variable
table(data$default)

#As we can see from the table, only 1 individual replied with "yes", that they have credit in default. 
#78.5% individuals answered "no" and 21.5% did not reply at all. Hence, this variable is of not much significance as we get no information from it. Thus, we would remove this from our dataset.

data2=data %>%
  select(-default)

#Education 

Crosstab(data2,"education","y")
#Removing missing values from the data, since less than 5% of the data has missing values for this field and the proportion of the response variable for these values is the same as the data at a whole. It is better to omit these values altogether.

data2=data2%>%
  filter(education!="missing")

#Housing

Crosstab(data2,"housing","y")

chisq.test(data2$housing,data2$y)

#Since, the chi-square test for this variable has p-value less than 0.05 there is a significant association with the response variable. Hence, we would keep this in our dataset.

#Removing missing values from the data, since less than 5% of the data has missing values for this field and the proportion of the response variable for these values is the same as the data at a whole. It is better to omit these values altogether.

data2=data2%>%
  filter(housing!="missing")

#Loan

Crosstab(data2,"loan","y")
chisq.test(data2$loan,data2$y)

#Since, the chi-square test for this variable has p-value more than 0.05 there is no significant association with the response variable. Hence, we would exclude this from our dataset.

data2= data2 %>%
  select(-loan)

#Job
table(data2$job)

Crosstab(data2,"job","y")

#Removing missing values from the data, since less than 5% of the data has missing values for this field and the proportion of the response variable for these values is the same as the data at a whole. It is better to omit these values altogether.

data2=data2%>%
  filter(job!="missing")

#Marital status

Crosstab(data2,"marital","y")

#Removing missing values from the data, since less than 5% of the data has missing values for this field and the proportion of the response variable for these values is the same as the data at a whole. It is better to omit these values altogether.

data2=data2%>%
  filter(marital!="missing")
dim(data2)
dim(data)

data2 %>% 
  summarise_all(list(~sum(. == "missing"))) %>% 
  gather(key = "variable", value = "no_missing") %>% 
  arrange(-no_missing)

#No missing values left in our final dataset.
```

```{r}
#Train-test split.Using 80%/20% split.
set.seed(123)

n=nrow(data2)
ind=sample(c(1:n),0.8*n)
data.train=data2[ind,]
data.test=data2[-ind,]

dim(data.train)
dim(data.test)
```

```{r}
#EXPLORATORY DATA ANALYSIS
#age
data.train %>% ggplot(aes(age)) +
  geom_histogram(color = 'white')
data.train %>% ggplot(aes(age, color = factor(y))) + 
  geom_density() +
  scale_x_continuous(breaks = seq(0, 100, 10)) +
  guides(color = guide_legend(title = 'Subscribed'))
#age group 30-58 more likely to say no. and more importantly
#product was subscribed with high likelihood after the age of ~60


#job
data.train %>% count(job) %>%
  ggplot(aes(y = fct_reorder(job, n), x = n))+
  geom_col() +
  labs(x = 'Count', y = 'Job') + 
  scale_x_continuous(breaks = seq(0, 2000, 200))

##comparison of proportion of 'yes' across job types
data.train %>% ggplot(aes(y = fct_rev(fct_infreq(job)), fill = y))+
     geom_bar(position = 'fill', color = 'black') +
     scale_fill_brewer(palette = 'Pastel1') +
     labs(x = 'proportion', y = 'Job')

#the high proportion of 'retired' job category resulting in 'yes'
#supports our previous observation related to age variable.


#marital
data.train %>% count(marital, y) %>% ungroup() %>%
  group_by(marital) %>% mutate(prop = n / sum(n)) %>%
  pivot_wider(names_from = y, values_from = c(n, prop))

data.train %>% ggplot(aes(x = marital, fill = y)) +
  geom_bar(position = 'fill', color = 'black') +
  scale_fill_brewer(palette = 'Pastel1')
#the proportion that resulted in 'yes' is not markedly different across marital status.


#education
data.train %>% ggplot(aes(y = education, y)) +
  geom_count() +
  labs(y = 'Education', x = 'count')
#Count of 'yes' for people with 'University degree' seems to be high

data.train %>% ggplot(aes(y = education, fill = y)) +
  geom_bar(position = 'fill')
#the proportion related to illiterate category is misleading because
#the overall sample size is very small
#other than that, 'university degree' and 'professional course' have a
#higher proportion


#housing
data.train %>% count(housing, y)

data.train %>% ggplot(aes(housing, fill = y)) + geom_bar(position = 'fill')

```



```{r}
#Contact
data.train %>% 
  ggplot() +
  aes(x = contact, y = after_stat(count)/nrow(data.train), fill = y) +
  geom_bar()

#Here, we can see that there have been more term deposits from cellular responders, 14.5% as compared to telephone responders which is just 5.6%.

#Month

Crosstab(data.train,"month","y")

data.train=data.train %>%
  mutate(month=factor(data.train$month,levels=c("jan","feb","mar","apr","may","jun","jul","aug","sep","oct",
                                                "nov","dec")))

data.train %>% 
  ggplot() +
  aes(x = month, y = after_stat(count)/nrow(data.train), fill = y) +
  geom_bar()

#From the barplot, we can see that there has been no contact in the months of January and February. Most contact has been made in May almost 33.7%, but most of the people declined to deposit here as well. Least contact has been made in December.

#Day of the week

Crosstab(data.train,"day_of_week","y")

data.train=data.train %>%
  mutate(day_of_week=factor(data.train$day_of_week,levels=c("mon","tue","wed","thu","fri","sat","sun")))

data.train %>% 
  ggplot() +
  aes(x = day_of_week, y = after_stat(count)/nrow(data.train), fill = y) +
  geom_bar()

#Duration

data.train=data.train %>%
  select(-duration)

#There doesn't seem to be a significant relationship between our response variable and duration. As our goal is to know how many people will subscribe to the term deposit, it is not really possible to know the duration of the call beforehand.


#Campaign

data.train %>%
  ggplot()+
  aes(x=campaign)+
  geom_bar()

#We can see that for more than 15 calls, every responder has declined for the term deposit. If we look at the data only for a total a 15 calls-

data.train %>%
  filter(campaign<=15) %>%
  ggplot()+
  aes(x=campaign)+
  geom_bar()

data.train = data.train %>%
  mutate(campaign=ifelse(campaign<=15,"Less Than 15","More Than 15"))

```

```{r}

# Pdays : Number of days passed after client was last contacted by a previous campaign

# Distribution of data
table(data.train$pdays)

# The number 999 means that the client has not been contacted before, this constitutes as the majority of the clients. 
# This variable can be used to check if previous contact with a client is beneficial, but we need to convert this variable

data.train = data.train %>%
              mutate(n_contact = if_else(pdays == 999,"no","yes")) %>%
              select(-pdays)

Crosstab(data.train,'n_contact','y')

chisq.test(data.train$n_contact,data.train$y)
# It seems that when a client is contacted before,they are more receptive towards saying Yes
# This is verified with the chisq test as well.

# previous : Number of times a client has been contacted before this campaign
table(data.train$previous)

# This variable will provide the same information after encoding it to whether or not a previous contact has been made with the client or not.

# Poutcome : Outcome of the previous campaign on the respective client.


table(data.train$poutcome)

Crosstab(data.train,'poutcome','y')

```

```{r}
# Exploratory Data Analysis

# All Continuous variables
#Histogram and density plot of the numerical variables

summary(data.train)

num_variables = c('age','emp.var.rate','cons.price.idx','cons.conf.idx','euribor3m','nr.employed')
library(GGally)

ggpairs(data.train,columns = num_variables)

corrplot(cor(data.train[num_variables]))

for (col in num_variables){
  
  plot = ggplot(data = data.train,aes(x = data.train[,col])) +
    geom_histogram() + labs(x = col)
  print(plot)
}


for(col in num_variables){
  plot <- ggplot(aes(y = data.train[, col]), data = data.train)+
    geom_boxplot(aes(color = y)) + labs(y = col, x = 'y')
  print(plot)
}
#boxplot for euribor3m, and emp.var.rate display some
#pattern

#the density plot for the two variables
data.train %>% ggplot(aes(x = euribor3m)) +
  geom_density(aes(color = y))

data.train %>% ggplot(aes(x = emp.var.rate)) +
  geom_density(aes(color = y))

#density plot for euribor3m shows some inherent difference
#between categories

#boxplot for emp.var.rate is misleading


Crosstab(data.train,"contact","y")
```

```{r}
data.train.num <- data.train %>%
  select(emp.var.rate, cons.price.idx, cons.conf.idx, euribor3m, nr.employed)

data.train.char <- data.train %>%
  select(campaign, job, marital, education, housing, contact, poutcome, n_contact, y)

min = sapply(data.train.num,min)
range = sapply(data.train.num, range)

data.train.num = (data.train.num-min)/ range


data.train.char <- data.train.char %>%
  map_dfc(as.factor)

data.train.scaled <- cbind(data.train %>% select(age, month, day_of_week, previous), data.train.char, data.train.num)

data.train.scaled <- data.train.scaled %>% 
  select(order(colnames(data.train.scaled)))

data.train.scaled %>% head()
```


```{r Test data}
data.test = data.test %>%
              mutate(n_contact = if_else(pdays == 999,"no","yes")) %>%
              select(-pdays)

data.test=data.test %>%
  mutate(month=factor(data.test$month,levels=c("jan","feb","mar","apr","may","jun","jul","aug","sep","oct",
                                                "nov","dec")))
data.test=data.test %>%
  mutate(day_of_week=factor(data.test$day_of_week,levels=c("mon","tue","wed","thu","fri","sat","sun")))

data.test = data.test %>%
  mutate(campaign=ifelse(campaign<=15,"Less Than 15","More Than 15"))

data.test.num <- data.test %>%
  select(emp.var.rate, cons.price.idx, cons.conf.idx, euribor3m, nr.employed)

data.test.char <- data.test %>%
  select(campaign, job, marital, education, housing, contact, poutcome, n_contact, y)

data.test.num = (data.test.num-min)/ range

data.test.char <- data.test.char %>%
  map_dfc(as.factor)

data.test.scaled <- cbind(data.test %>% select(age, month, day_of_week,previous), data.test.char, data.test.num)

data.test.scaled <- data.test.scaled %>% 
  select(order(colnames(data.test.scaled)))

data.test.scaled %>% head()
names(data.test.scaled)
names(data.train.scaled)

```
```{r cleaning environment}
rm(data.test.char)
rm(data.test.num)
rm(data.train.char)
rm(data.train.num)
rm(data.test)
rm(data.train)
rm(plot)
rm(col)
rm(range)
rm(num_variables)
rm(ind)
rm(min)
rm(n)
```

```{r}
#Tree Based Methods

tune_grid = expand.grid(
  cp = seq(from = 0, to = 0.01, by = 0.001)
)

tune_control = trainControl(
  method = "cv", # cross-validation
  number = 3, # with n folds 
  summaryFunction = prSummary,
  verboseIter = FALSE, # no training log
  allowParallel = FALSE, # FALSE for reproducible results 
  classProbs = TRUE
)

rpart1_tune = train(
  y ~ .,
  data = data.train.scaled,
  metric = "F",
  trControl = tune_control,
  tuneGrid = tune_grid,
  method = "rpart")

ggplot(rpart1_tune) +
  theme(legend.position = "bottom")

tree <- rpart(y ~ ., data = data.train.scaled, cp = rpart1_tune$bestTune)

rpart.plot(tree)
```


```{r}
# plotting importance from predictive models into two panels
fun_imp_ggplot_split = function(model){
  # model: model used to plot variable importances
  
  if (class(model)[1] == "ranger"){
    imp_df = model$variable.importance %>% 
      data.frame("Overall" = .) %>% 
      rownames_to_column() %>% 
      rename(variable = rowname) %>% 
      arrange(-Overall)
  } else {
    imp_df = varImp(model) %>%
      rownames_to_column() %>% 
      rename(variable = rowname) %>% 
      arrange(-Overall)
  }
  
  # first panel (half most important variables)
  gg1 = imp_df %>% 
    slice(1:floor(nrow(.)/2)) %>% 
    ggplot() +
    aes(x = reorder(variable, Overall), weight = Overall, fill = -Overall) +
    geom_bar() +
    coord_flip() +
    xlab("Variables") +
    ylab("Importance") +
    theme(legend.position = "none")
    
  imp_range = ggplot_build(gg1)[["layout"]][["panel_params"]][[1]][["x.range"]]
  imp_gradient = scale_fill_gradient(limits = c(-imp_range[2], -imp_range[1]),
                                     low = "#132B43", 
                                     high = "#56B1F7")
  
  # second panel (less important variables)
  gg2 = imp_df %>% 
    slice(floor(nrow(.)/2)+1:nrow(.)) %>% 
    ggplot() +
    aes(x = reorder(variable, Overall), weight = Overall, fill = -Overall) +
    geom_bar() +
    coord_flip() +
    xlab("") +
    ylab("Importance") +
    theme(legend.position = "none") +
    ylim(imp_range) +
    imp_gradient
  
  # arranging together
  gg_both = plot_grid(gg1 + imp_gradient,
                      gg2)
  
  return(gg_both)
}


# plotting two performance measures
fun_gg_cutoff = function(score, obs, measure1, measure2) {
  # score: predicted scores
  # obs: real classes
  # measure1, measure2: which performance metrics to plot
  
  predictions = prediction(score, obs)
  performance1 = performance(predictions, measure1)
  performance2 = performance(predictions, measure2)
  
  df1 = data.frame(x = performance1@x.values[[1]],
                   y = performance1@y.values[[1]],
                   measure = measure1,
                   stringsAsFactors = F) %>% 
    drop_na()
  df2 = data.frame(x = performance2@x.values[[1]],
                   y = performance2@y.values[[1]],
                   measure = measure2,
                   stringsAsFactors = F) %>% 
    drop_na()
  
  # df contains all the data needed to plot both curves
  df = df1 %>% 
    bind_rows(df2)
    
  # extracting best cut for each measure
  y_max_measure1 = max(df1$y, na.rm = T)
  x_max_measure1 = df1[df1$y == y_max_measure1, "x"][1]
  
  y_max_measure2 = max(df2$y, na.rm = T)
  x_max_measure2 = df2[df2$y == y_max_measure2, "x"][1]
  
  txt_measure1 = paste("Best cut for", measure1, ": x =", round(x_max_measure1, 3))
  txt_measure2 = paste("Best cut for", measure2, ": x =", round(x_max_measure2, 3))
  txt_tot = paste(txt_measure1, "\n", txt_measure2, sep = "")
  
  # plotting both measures in the same plot, with some detail around.
  gg = df %>% 
    ggplot() +
    aes(x = x,
        y = y,
        colour = measure) +
    geom_line() +
    geom_vline(xintercept = c(x_max_measure1, x_max_measure2), linetype = "dashed", color = "gray") +
    geom_hline(yintercept = c(y_max_measure1, y_max_measure2), linetype = "dashed", color = "gray") +
    labs(caption = txt_tot) +
    theme(plot.caption = element_text(hjust = 0)) +
    xlim(c(0, 1)) +
    ylab("") +
    xlab("Threshold")
    
  return(gg)
}
  
# creating classes according to score and cut
fun_cut_predict = function(score, cut) {
  # score: predicted scores
  # cut: threshold for classification
  
  classes = score
  classes[classes > cut] = 1
  classes[classes <= cut] = 0
  classes = as.factor(classes)
  
  return(classes)  
}

fun_imp_ggplot_split(tree)
```


```{r}
tree_train_score = predict(tree,
                           newdata = data.train.scaled,
                           type = "prob")[, 2]

tree_test_score = predict(tree,
                          newdata = data.test.scaled,
                          type = "prob")[, 2]

measure_train = fun_gg_cutoff(tree_train_score, data.train.scaled$y, 
                              "acc", "f")
measure_train +
  geom_vline(xintercept = c(0.25, 0.5), 
             linetype = "dashed")
```
```{r}

data.train.scaled_1 = data.train.scaled %>% 
  mutate(y = factor(if_else(y == "yes", "1", "0"), 
                    levels = c("0", "1")))
tree_train_cut = 0.25
tree_train_class = fun_cut_predict(tree_train_score, tree_train_cut)
tree_train_confm = confusionMatrix(tree_train_class, data.train.scaled_1$y, 
                                   positive = "1",
                                   mode = "everything")
tree_train_confm

```
```{r}
#Random Forest

tune_grid = expand.grid(
  mtry = c(1:(floor(ncol(data.train.scaled) * 0.7))),
  splitrule = c("gini", "extratrees"),
  min.node.size = 1
)

tune_control = trainControl(
  method = "cv", # cross-validation
  number = 3, # with n folds 
  summaryFunction = prSummary,
  verboseIter = FALSE, # no training log
  allowParallel = FALSE, # FALSE for reproducible results 
  classProbs = TRUE
)

ranger_tune = train(
  y ~ .,
  data = data.train.scaled,
  metric = "F",
  trControl = tune_control,
  tuneGrid = tune_grid,
  method = "ranger"
)

str(data.train.scaled)

ggplot(ranger_tune) +
  theme(legend.position = "bottom")

rf = ranger(y ~ .,
            data = data.train.scaled,
            num.trees = 1000,
            importance = "impurity",
            splitrule = ranger_tune$bestTune$splitrule,
            mtry = ranger_tune$bestTune$mtry,
            min.node.size = ranger_tune$bestTune$min.node.size,
            write.forest = T,
            probability = T)

```


```{r}
print(rf)
```


```{r}
fun_imp_ggplot_split(rf)
```
```{r}
rf_train_score = predict(rf,
                         data = data.train.scaled)$predictions[, 2]

rf_test_score = predict(rf,
                        data = data.train.scaled)$predictions[, 2]

measure_train = fun_gg_cutoff(rf_train_score, data.train.scaled$y, 
                              "acc", "f")
measure_train +
  geom_vline(xintercept = c(0.3, 0.5), 
             linetype = "dashed")
measure_train = fun_gg_cutoff(rf_train_score, data.train.scaled$y, 
                              "acc", "f")
measure_train +
  geom_vline(xintercept = c(0.3, 0.5), 
             linetype = "dashed")
```
```{r}
rf_train_cut = 0.3
rf_train_class = fun_cut_predict(rf_train_score, rf_train_cut)
# matrix
rf_train_confm = confusionMatrix(rf_train_class, data.train.scaled_1$y, 
                                 positive = "1",
                                 mode = "everything")
rf_train_confm
```

