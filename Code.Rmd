---
title: "EDA Code"
author: "Shreyansi Jain"
date: "2023-03-07"
output: html_document
---

```{r setup, include=FALSE, echo = FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#setwd("~/Desktop/Semester 2/DMML Project/DMML_Group14")
```

```{r libraries}
library(gmodels) # Cross Tables [CrossTable()]
library(ggmosaic) # Mosaic plot with ggplot [geom_mosaic()]
library(corrplot) # Correlation plot [corrplot()]
library(ggpubr) # Arranging ggplots together [ggarrange()]
library(cowplot) # Arranging ggplots together [plot_grid()]
library(caret) # ML [train(), confusionMatrix(), createDataPartition(), varImp(), trainControl()]
library(ROCR) # Model performance [performance(), prediction()]
library(plotROC) # ROC Curve with ggplot [geom_roc()]
library(pROC) # AUC computation [auc()]
library(PRROC) # AUPR computation [pr.curve()]
library(rpart) # Decision trees [rpart(), plotcp(), prune()]
library(rpart.plot) # Decision trees plotting [rpart.plot()]
library(ranger) # Optimized Random Forest [ranger()]
library(lightgbm) # Light GBM [lgb.train()]
library(xgboost) # XGBoost [xgb.DMatrix(), xgb.train()]
library(MLmetrics) # Custom metrics (F1 score for example)
library(tidyverse) # Data manipulation
library(doMC) # Parallel processing
```


```{r}
data = read.csv("group_14.csv")
data=replace(data,data=='',"missing")
head(data)
data %>% 
  summarise_all(list(~sum(. == "missing"))) %>% 
  gather(key = "variable", value = "no_missing") %>% 
  arrange(-no_missing)

#Defining crosstable to be used in our analysis
Crosstab = function(df, var1, var2){
  # df: dataframe containing both columns to cross
  # var1, var2: columns to cross together.
  CrossTable(df[, var1], df[, var2],
             prop.r = T,
             prop.c = F,
             prop.t = F,
             prop.chisq = F,
             dnn = c(var1, var2))
}

```
```{r}
#Treating missing values

#Default variable
table(data$default)

#As we can see from the table, only 1 individual replied with "yes", that they have credit in default. 
#78.5% individuals answered "no" and 21.5% did not reply at all. Hence, this variable is of not much significance as we get no information from it. Thus, we would remove this from our dataset.

data2=data %>%
  select(-default)

#Education 

Crosstab(data2,"education","y")
#Removing missing values from the data, since less than 5% of the data has missing values for this field and the proportion of the response variable for these values is the same as the data at a whole. It is better to omit these values altogether.

data2=data2%>%
  filter(education!="missing")

#Housing

Crosstab(data2,"housing","y")

chisq.test(data2$housing,data2$y)

#Since, the chi-square test for this variable has p-value less than 0.05 there is a significant association with the response variable. Hence, we would keep this in our dataset.

#Removing missing values from the data, since less than 5% of the data has missing values for this field and the proportion of the response variable for these values is the same as the data at a whole. It is better to omit these values altogether.

data2=data2%>%
  filter(housing!="missing")

#Loan

Crosstab(data2,"loan","y")
chisq.test(data2$loan,data2$y)

#Since, the chi-square test for this variable has p-value more than 0.05 there is no significant association with the response variable. Hence, we would exclude this from our dataset.

data2= data2 %>%
  select(-loan)

#Job
table(data2$job)

Crosstab(data2,"job","y")

#Removing missing values from the data, since less than 5% of the data has missing values for this field and the proportion of the response variable for these values is the same as the data at a whole. It is better to omit these values altogether.

data2=data2%>%
  filter(job!="missing")

#Marital status

Crosstab(data2,"marital","y")

#Removing missing values from the data, since less than 5% of the data has missing values for this field and the proportion of the response variable for these values is the same as the data at a whole. It is better to omit these values altogether.

data2=data2%>%
  filter(marital!="missing")
dim(data2)
dim(data)

data2 %>% 
  summarise_all(list(~sum(. == "missing"))) %>% 
  gather(key = "variable", value = "no_missing") %>% 
  arrange(-no_missing)

#No missing values left in our final dataset.
```

```{r}
#Train-test split.Using 80%/20% split.
set.seed(123)

n=nrow(data2)
ind=sample(c(1:n),0.8*n)
data.train=data2[ind,]
data.test=data2[-ind,]

dim(data.train)
dim(data.test)
```

```{r}
#EXPLORATORY DATA ANALYSIS

#age
data.train %>% ggplot(aes(age)) +
  geom_histogram(color = 'white')

data.train %>% ggplot(aes(age, color = factor(y))) + 
  geom_density() +
  scale_x_continuous(breaks = seq(0, 100, 10)) +
  guides(color = guide_legend(title = 'Subscribed'))
#age group 30-58 more likely to say no. and more importantly
#product was subscribed with high likelihood after the age of ~60

#job
data.train %>% count(job) %>%
  ggplot(aes(y = fct_reorder(job, n), x = n))+
  geom_col() +
  labs(x = 'Count', y = 'Job') + 
  scale_x_continuous(breaks = seq(0, 2000, 200))

##comparison of proportion of 'yes' across job types
data.train %>% ggplot(aes(y = fct_rev(fct_infreq(job)), fill = y))+
     geom_bar(position = 'fill', color = 'black') +
     scale_fill_brewer(palette = 'Pastel1') +
     labs(x = 'proportion', y = 'Job')

#the high proportion of 'retired' job category resulting in 'yes'
#supports our previous observation related to age variable.


#marital
data.train %>% count(marital, y) %>% ungroup() %>%
  group_by(marital) %>% mutate(prop = n / sum(n)) %>%
  pivot_wider(names_from = y, values_from = c(n, prop))

data.train %>% ggplot(aes(x = marital, fill = y)) +
  geom_bar(position = 'fill', color = 'black') +
  scale_fill_brewer(palette = 'Pastel1')
#the proportion that resulted in 'yes' is not markedly different across marital status.


#education
data.train %>% ggplot(aes(y = education, y)) +
  geom_count() +
  labs(y = 'Education', x = 'count')
#Count of 'yes' for people with 'University degree' seems to be high

data.train %>% ggplot(aes(y = education, fill = y)) +
  geom_bar(position = 'fill')
#the proportion related to illiterate category is misleading because
#the overall sample size is very small
#other than that, 'university degree' and 'professional course' have a
#higher proportion


#housing
data.train %>% count(housing, y)

data.train %>% ggplot(aes(housing, fill = y)) + geom_bar(position = 'fill')
```